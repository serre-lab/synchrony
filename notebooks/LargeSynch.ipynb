{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "plt.style.use('ggplot')\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from scipy.special import softmax as np_softmax\n",
    "from scipy.linalg import toeplitz, circulant\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import uniform, cauchy, normal, relaxed_bernoulli\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1 + torch.exp(-1*(x)))\n",
    "\n",
    "def normalize(x):\n",
    "    return x / torch.sqrt((x**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch distribution objects for intrinsic frequencies\n",
    "\n",
    "def get_dist(dist_name,):\n",
    "    if dist_name == 'cauchy':\n",
    "        loc = 0.0\n",
    "        scale = 1.0\n",
    "        dist = cauchy.Cauchy(loc, scale)\n",
    "        g0 = torch.exp(dist.log_prob(loc))\n",
    "        return dist, g0\n",
    "    elif dist_name == 'uniform':\n",
    "        high = 1.0\n",
    "        low = -1.0\n",
    "        g0 = 1. / (high - low)\n",
    "        dist = uniform.Uniform(-1.0, 1.0)\n",
    "        return dist, g0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Networks\n",
    "\n",
    "# Predict connectivity from omega\n",
    "class connectivity_net(torch.nn.Module):\n",
    "    def __init__(self, num_in, num_out, num_hid_units=256, num_hid_layers=1,transform=None):\n",
    "        super(connectivity_net, self).__init__()\n",
    "        self.transform=transform\n",
    "        self.num_out = num_out\n",
    "        self.layers = torch.nn.ModuleList([torch.nn.Linear(num_in, num_hid_units),\n",
    "                         torch.nn.ReLU()])\n",
    "        for _ in range(num_hid_layers):\n",
    "            self.layers.extend([torch.nn.Linear(num_hid_units, num_hid_units),torch.nn.ReLU()])\n",
    "        self.layers.append(torch.nn.Linear(num_hid_units,self.num_out))\n",
    "    def forward(self,x):   \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        if self.transform == 'softmax':\n",
    "            x = softmax(x,dim=-1)\n",
    "        elif self.transform == 'sigmoid':\n",
    "            x = sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class connectivity_GRU(torch.nn.Module):\n",
    "    def __init__(self, num_in, num_out, num_hid_units=256,num_hid_layers=1, T=10, transform=None):\n",
    "        super(connectivity_GRU, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.num_hid_units = num_hid_units\n",
    "        self.num_hid_layers = num_hid_layers\n",
    "        self.T = T\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.gru = torch.nn.GRU(num_in, num_hid_units, num_hid_layers,)\n",
    "        self.fc = torch.nn.Linear(self.num_hid_units, self.num_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        x = torch.stack([x for _ in range(self.T)])\n",
    "        out, h = self.gru(x, h)\n",
    "        \n",
    "        out = torch.stack([self.fc(self.relu(out[i, ...])) for i in range(self.T)])\n",
    "        if self.transform == 'softmax':\n",
    "            out = softmax(out,dim=-1)\n",
    "        elif self.transform == 'sigmoid':\n",
    "            out = sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.num_hid_layers, batch_size, self.num_hid_units).zero_()\n",
    "        return hidden\n",
    "    \n",
    "class connectivity_cGRU(torch.nn.Module):\n",
    "    def __init__(self, num_in, num_out, num_hid_units=256,num_hid_layers=1, transform=None, feedback=False):\n",
    "        super(connectivity_cGRU, self).__init__()\n",
    "        self.num_out = num_out\n",
    "        self.num_hid_units = num_hid_units\n",
    "        self.num_hid_layers = num_hid_layers\n",
    "        self.transform = transform\n",
    "        self.feedback = feedback\n",
    "        \n",
    "        gru_in = 2*num_in if feedback else num_in\n",
    "        self.gru = torch.nn.GRU(gru_in, num_hid_units, num_hid_layers,)\n",
    "        self.fc = torch.nn.Linear(self.num_hid_units, self.num_out)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, omega, h, phase, coupling_strength=.3, alpha=1e-1,\n",
    "                GRU_steps=10, kuramoto_steps=100, return_connectivities=False):\n",
    "        phase_trajectory = []\n",
    "        connectivities = []\n",
    "        if self.feedback:\n",
    "            for t in range(kuramoto_steps):\n",
    "                data = torch.cat([omega, phase], dim=-1).unsqueeze(0)\n",
    "                out, h = self.gru(data,h)\n",
    "                out = self.fc(self.relu(out.squeeze(0)))\n",
    "                if self.transform == 'softmax':\n",
    "                    out = softmax(out,dim=-1)\n",
    "                elif self.transform == 'sigmoid':\n",
    "                    out = sigmoid(out)\n",
    "\n",
    "                connectivity = make_connectivity(out)\n",
    "                if return_connectivities:\n",
    "                    connectivities.append(connectivity)\n",
    "                phase = kuramoto_step(phase, coupling_strength*connectivity, omega, alpha=alpha)\n",
    "                phase_trajectory.append(phase)        \n",
    "\n",
    "            if return_connectivities:\n",
    "                return phase_trajectory, connectivities\n",
    "            else:\n",
    "                return phase_trajectory\n",
    "        else:\n",
    "            data = torch.stack([omega for _ in range(GRU_steps)])\n",
    "            out, h = self.gru(data, h)\n",
    "\n",
    "            out = torch.stack([self.fc(self.relu(out[i, ...])) for i in range(GRU_steps)])\n",
    "            if self.transform == 'softmax':\n",
    "                out = softmax(out,dim=-1)\n",
    "            elif self.transform == 'sigmoid':\n",
    "                out = sigmoid(out)\n",
    "            connectivity = make_connectivity(out[-1,...])\n",
    "            if return_connectivities:\n",
    "                connectivities.append(connectivity)\n",
    "                \n",
    "            for t in range(kuramoto_steps):\n",
    "                phase = kuramoto_step(phase, coupling_strength*connectivity, omega, alpha=alpha)\n",
    "                phase_trajectory.append(phase)  \n",
    "                \n",
    "            if return_connectivities:\n",
    "                return phase_trajectory, connectivities\n",
    "            else:\n",
    "                return phase_trajectory\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.num_hid_layers, batch_size, self.num_hid_units).zero_()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize connectivity network\n",
    "\n",
    "def optimize_connectivity_cgru(num_units, num_out, num_links, omega_name='uniform',iterations=100,\n",
    "                              transform=None,kuramoto_steps=100,\n",
    "                              burn_in_steps = 75, lr=.01, alpha=.1,coupling_strength = .7,\n",
    "                              num_hid_units=256, num_hid_layers=1,batch_size=256,optimizer='Adam',\n",
    "                              view_inner_opt=-1,view_lr=-1, view_connectivities=-1, GRU_steps=10,\n",
    "                              feedback=False, verbose=0, pretrained=False):\n",
    "    \n",
    "    \n",
    "    # Initial stuff\n",
    "    omega_dist, g0 = get_dist(omega_name)\n",
    "    cn = connectivity_cGRU(num_units, num_out, num_hid_units=num_hid_units,\n",
    "                          num_hid_layers=num_hid_layers, transform=transform, feedback=feedback)\n",
    "    if pretrained:\n",
    "        cn.load_state_dict(torch.load('/media/data_cifs_lrs/projects/prj_synchrony/results/models/brede.pt'))\n",
    "    \n",
    "    if optimizer=='Adam':\n",
    "        opt = torch.optim.Adam(cn.parameters(), lr=lr)\n",
    "    elif optimizer=='SGD':\n",
    "        opt = torch.optim.SGD(cn.parameters(), lr=lr)\n",
    "\n",
    "    cvh = []\n",
    "    co  = []\n",
    "    pn  = []\n",
    "    oh  = []\n",
    "    ioh = []\n",
    "    ah  = []\n",
    "    \n",
    "    triu_ind = torch.triu_indices(row=num_units, col=num_units, offset=1)\n",
    "    for i in range(iterations):\n",
    "        start = time.time()\n",
    "        omega = omega_dist.sample(sample_shape=torch.Size([batch_size,num_units]))\n",
    "        opt.zero_grad()\n",
    "\n",
    "        phase = np.pi * torch.ones(batch_size,num_units)\n",
    "        h = cn.init_hidden(batch_size)\n",
    "        \n",
    "        if view_connectivities and i == (iterations - 1):\n",
    "            flow, connectivities = cn.forward(omega, h, phase, kuramoto_steps=kuramoto_steps, GRU_steps=GRU_steps,\n",
    "                                              coupling_strength=coupling_strength, return_connectivities=True)\n",
    "        else:\n",
    "            flow = cn.forward(omega, h, phase, kuramoto_steps=kuramoto_steps, GRU_steps=GRU_steps,\n",
    "                              coupling_strength=coupling_strength)\n",
    "        \n",
    "        flow = torch.stack(flow).transpose(1,0)\n",
    "        truncated_flow = flow[:,burn_in_steps:,:]\n",
    "        cv = circular_variance(truncated_flow)\n",
    "        cvh.append(cv.detach().cpu().numpy())\n",
    "        cv.backward()\n",
    "        opt.step()\n",
    "        stop = time.time()\n",
    "        if verbose:\n",
    "            print('Iteration {}. Loss: {}. Time/batch: {}'.format(i, cv.detach().numpy(), stop-start))\n",
    "\n",
    "        if cv != cv:\n",
    "            ipdb.set_trace()\n",
    "           \n",
    "    return cvh, cn, connectivities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
