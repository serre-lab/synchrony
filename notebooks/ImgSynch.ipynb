{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import softmax\n",
    "from torch.distributions import uniform, cauchy, normal, relaxed_bernoulli\n",
    "from scipy.linalg import toeplitz, circulant\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.collections import PatchCollection\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class coupling_network(torch.nn.Module):\n",
    "    def __init__(self,num_features=32, img_side=32, kernel_size=5):\n",
    "        super(coupling_network, self).__init__()\n",
    "        self.img_side = img_side\n",
    "        self.num_features = num_features\n",
    "        self.padding = torch.nn.ZeroPad2d(int((kernel_size - 1) / 2))\n",
    "        self.conv = torch.nn.Conv2d(1,num_features,kernel_size,stride=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.padding(x)\n",
    "        x = self.conv(x).reshape(batch_size, self.num_features, -1)\n",
    "        x = torch.einsum('bci,bcj->bij', x, x)/ self.num_features\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circular_moments_batch(phases, masks):\n",
    "    num_groups = masks.shape[1]\n",
    "    group_size = masks.sum(2)\n",
    "    group_size = torch.where(group_size == 0, torch.ones_like(group_size), group_size)\n",
    "    T = phases.shape[0]\n",
    "    masked_phases = phases.unsqueeze(2) * masks.unsqueeze(0)\n",
    "    xx = torch.where(masks.bool(), torch.cos(masked_phases), torch.zeros_like(masked_phases))\n",
    "    yy = torch.where(masks.bool(), torch.sin(masked_phases), torch.zeros_like(masked_phases))\n",
    "    go = torch.sqrt((xx.sum(-1))**2 + (yy.sum(-1))**2) / group_size\n",
    "    synch = 1 - go.sum(2)/num_groups\n",
    "    \n",
    "    mean_angles = torch.atan2(yy.sum(-1), xx.sum(-1))\n",
    "    desynch = 0\n",
    "    \n",
    "    for m in np.arange(1, int(np.floor(num_groups/2.)) + 1):\n",
    "#         K_m = 1 if m < int(np.floor(num_groups/2.)) + 1 else -1\n",
    "        desynch += (1.0 / (2*num_groups * m**2)) * (torch.cos(m*mean_angles).sum(-1)**2 + torch.sin(m*mean_angles).sum(-1)**2)\n",
    "#     loss = .5*(synch + desynch)\n",
    "    loss = desynch\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data\n",
    "def make_data(num_samples, num_cells=12, num_textures=4, img_side=32):\n",
    "    cells_per_texture = int(num_cells / num_textures)\n",
    "    gray=True\n",
    "    all_imgs = []\n",
    "    all_masks = []\n",
    "    for s in range(num_samples):\n",
    "        yy = torch.linspace(0,img_side-1, img_side).int()\n",
    "        xx = torch.linspace(0,img_side-1, img_side).int()\n",
    "        grid = torch.meshgrid(yy,xx)\n",
    "        points = torch.randint(0, img_side, size=(num_cells, 2)).float()\n",
    "        dists = []\n",
    "        gray_levels = torch.randperm(255)[:num_textures]\n",
    "        exploded_gray_levels = []\n",
    "        for i in range(num_textures):\n",
    "            exploded_gray_levels += int(num_cells / num_textures) * [gray_levels[i]]\n",
    "        imgs = [exploded_gray_levels[i]*torch.ones((img_side, img_side)) for i in range(num_cells)]\n",
    "        for p in points:\n",
    "            dists.append(torch.sqrt((p[0] - grid[0])**2 + (p[1] - grid[1])**2))\n",
    "        dists = torch.stack(dists)\n",
    "        masks = [torch.argmin(dists,axis=0) == i for i in range(len(points))]\n",
    "        composite = torch.stack([mask.unsqueeze(-1)*image for (mask,image) in zip(masks, imgs)]).sum(0)\n",
    "        stacked_masks = torch.stack(masks)\n",
    "        eq_masks = torch.stack([stacked_masks[i*cells_per_texture:(i+1)*cells_per_texture].sum(0) for i in range(num_textures)])\n",
    "        all_imgs.append(composite.mean(-1))\n",
    "        all_masks.append(eq_masks)\n",
    "    return torch.stack(all_imgs), torch.stack(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kuramoto_step(phase, coupling, omega, alpha=.01):\n",
    "    phase_diffs = torch.sin(phase.unsqueeze(-1) - phase.unsqueeze(-2))\n",
    "    delta = alpha * (omega + (coupling * phase_diffs).mean(1))\n",
    "    return phase + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making data\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Make Data\n",
    "img_side=32\n",
    "num_training= 200\n",
    "num_testing = 50\n",
    "print('Making data')\n",
    "training_imgs, training_masks = make_data(num_training, img_side=img_side)\n",
    "testing_imgs, testing_masks = make_data(num_testing, img_side=img_side)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_epochs = 10\n",
    "kuramoto_steps=100\n",
    "burn_in_steps=95\n",
    "num_features=25\n",
    "lr = 1e-4\n",
    "alpha = 1e-1\n",
    "sigma = 1.0\n",
    "num_batches = int(num_training / batch_size)\n",
    "cn = coupling_network(num_features=num_features, img_side=32)\n",
    "opt = torch.optim.Adam(cn.parameters(), lr=lr)\n",
    "lh = []\n",
    "omega = torch.zeros((batch_size, img_side**2))\n",
    "for n in range(num_batches):\n",
    "    opt.zero_grad()\n",
    "    batch = training_imgs[n*batch_size:(n+1)*batch_size,...] / 255.\n",
    "    batch = batch.unsqueeze(1)\n",
    "    masks = training_masks[n*batch_size:(n+1)*batch_size,...].reshape(batch_size, 4, -1)\n",
    "    coupling = sigma*cn.forward(batch)\n",
    "    init_phase = torch.normal(np.pi, .1, size=(batch_size, img_side**2))\n",
    "    phase = init_phase\n",
    "    flow = []\n",
    "    for k in range(kuramoto_steps):\n",
    "        phase = kuramoto_step(phase, coupling, omega, alpha=alpha)\n",
    "        flow.append(phase)\n",
    "    flow = torch.stack(flow)\n",
    "    truncated_flow = flow[burn_in_steps:,...]\n",
    "    loss = circular_moments_batch(truncated_flow, masks)\n",
    "    lh.append(loss.detach().cpu().numpy())\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "plt.plot(lh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(lh).min())\n",
    "plt.plot(flow[:,0,...].detach().numpy(), color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
